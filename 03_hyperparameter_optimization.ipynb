{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90993daf-d79b-4fc6-9270-99cffde84ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fef0d38-10db-4b8e-b3b5-85e85a36d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 16:19:26.035459: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-28 16:19:26.035536: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-28 16:19:26.035542: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-28 16:19:26.041602: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf   # Import the TensorFlow library, which provides tools for machine learning and deep learning.\n",
    "import pandas as pd  # Import the pandas library, used for data manipulation and analysis.\n",
    "\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting and visualization.\n",
    "# This line allows for the display of plots directly within the Jupyter notebook interface.\n",
    "%matplotlib inline  \n",
    " \n",
    "# Import Keras libraries\n",
    "from tensorflow.keras.models import Sequential  # Import the Sequential model: a linear stack of layers from Keras module in TensorFlow.\n",
    "from tensorflow.keras.layers import Dense  # Import the Dense layer: a fully connected neural network layer from Keras module in TensorFlow.\n",
    "from tensorflow.keras.layers import Flatten  # Import the Flatten layer: used to convert input data into a 1D array from Keras module in TensorFlow.\n",
    "from tensorflow.keras import layers # Import the whole layers library\n",
    "from tensorflow.keras import losses # Import the different loss functions\n",
    "from sklearn.metrics import confusion_matrix # Import the confusion matrix library\n",
    "import numpy as np # Import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c49e0650-d63c-4ba4-b3f7-f8ced3670cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_display_data(path, batch_size=32, shape=(80,80,3), show_pictures=True):\n",
    "    # Define the directory path\n",
    "    directory_path = path\n",
    "    \n",
    "    # Define the batch size\n",
    "    batch_size = batch_size\n",
    "    \n",
    "    # Define the image size using the 1st 2 elements of the shape parameter\n",
    "    # We don't need the number of channels here, just the dimensions to use\n",
    "    image_size = shape[:2]\n",
    "    \n",
    "    # Load the dataset\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory_path,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=123,\n",
    "        labels='inferred',\n",
    "        label_mode='int'\n",
    "    )\n",
    "\n",
    "    if show_pictures:\n",
    "        # Get the class names\n",
    "        class_names = dataset.class_names\n",
    "        \n",
    "        # Display 3 images from each of the 2 categories\n",
    "        for i in range(2):\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            for images, labels in dataset.take(1):\n",
    "                images = images.numpy()\n",
    "                labels = labels.numpy()\n",
    "                for j in range(3):\n",
    "                    ax = plt.subplot(3, 3, j + 1)\n",
    "                    plt.imshow(images[labels == i][j].astype(\"uint8\"))\n",
    "                    plt.title(class_names[i])\n",
    "                    plt.axis(\"off\")\n",
    "            plt.show()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab69ef16-0273-45e9-a5c5-872d4ecb1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(activation='relu', shape=(80,80,3), num_classes=2):\n",
    "    '''A function to set up a model. \n",
    "          Takes in an activation function, shape for the input images, and number of classes.'''\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation=activation, input_shape=shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation=activation),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=activation),\n",
    "        layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32b0e1c2-d4c8-4745-8ece-f130e1bed693",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparseCategoricalCrossentropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile_train_model\u001b[39m(dataset, model,\n\u001b[0;32m----> 2\u001b[0m                         loss\u001b[38;5;241m=\u001b[39m\u001b[43mSparseCategoricalCrossentropy\u001b[49m(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      3\u001b[0m                         optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      7\u001b[0m                   loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m      8\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SparseCategoricalCrossentropy' is not defined"
     ]
    }
   ],
   "source": [
    "def compile_train_model(dataset, model,\n",
    "                        loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        optimizer='adam'):\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    # Train the model\n",
    "    history = model.fit(dataset, epochs=10, validation_data=dataset, validation_split=0.2)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c72ef72-2d6b-404b-b3af-2e683bff8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataset, model, history, num_classes=classes):\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(dataset)\n",
    "    print(f'Test loss: {loss}')\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "    # Plot the training and validation loss over time\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the training and validation accuracy over time\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Get the class names\n",
    "    class_names = dataset.class_names\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = np.argmax(model.predict(dataset), axis=-1)\n",
    "    \n",
    "    # Get the true labels\n",
    "    y_true = np.concatenate([y for x, y in dataset], axis=0)\n",
    "    \n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks([0, 1], class_names)\n",
    "    plt.yticks([0, 1], class_names)\n",
    "    plt.colorbar()\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee5fbaf3-5314-478f-8fcc-e6fe7a7b8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_whole_shabang(path, batch_size, shape, activation, loss, optimizer,show_pictures):\n",
    "    \n",
    "    dataset = load_display_data(path, batch_size=batch_size, shape=shape, show_pitures)\n",
    "    model = make_model(activation=activation, shape=shape, num_classes=classes)\n",
    "    model, history = compile_train_model(dataset, model, loss=loss,\n",
    "                        optimizer=optimizer)\n",
    "    evaluate_model(dataset, model, history, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12bb51fa-37ff-4302-993e-8354bee706de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparseCategoricalCrossentropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;66;03m# Only change this if you change the dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# The activation function is an important hyperparameter\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[43mSparseCategoricalCrossentropy\u001b[49m(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madagrad\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# adam, RMSprop, adagrad \u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Run everything with these hyperparameters\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SparseCategoricalCrossentropy' is not defined"
     ]
    }
   ],
   "source": [
    "path = 'data/ships/shipsnet/' # Path to the data.\n",
    "                              # Only change this if you change the dataset or where it is located\n",
    "\n",
    "show_pictures = False # Show sample images from the dataset? Keep on at first, but may become distracting.\n",
    "                     # Set to False to turn off\n",
    "# Hyperparameters\n",
    "shape = (80,80,3)  # Dimensions to use for the images...the raw data are 80x80\n",
    "                   #  color images, but you could down-sample them\n",
    "                   #  or convert them to black and white if you wanted\n",
    "batch_size = 32  # What batch size to use\n",
    "classes = 2 # We have 2 classes in our example: ship and no_ship. \n",
    "            # Only change this if you change the dataset\n",
    "activation='relu' # The activation function is an important hyperparameter\n",
    "\n",
    "loss=SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer='adagrad'  # adam, RMSprop, adagrad \n",
    "\n",
    "# Run everything with these hyperparameters\n",
    "the_whole_shabang(path, batch_size, shape, activation, loss, optimizer, show_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c200168-e1f0-4324-8df1-c2efc893c8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.14",
   "language": "python",
   "name": "tensorflow-2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
