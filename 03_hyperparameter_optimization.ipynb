{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90993daf-d79b-4fc6-9270-99cffde84ec4",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true) <img src='https://github.com/PracticumAI/practicumai.github.io/blob/main/images/icons/practicumai_beginner.png?raw=true' align='right' width=50 padding=50>\n",
    "***\n",
    "# *Practicum AI:* Hyperparameter Optimization\n",
    "\n",
    "In this notebook we'll be training an image classification model, and then playing around with it's hyperparameters (input shape, batch size, activation function, loss function and optimizer). To create the model we'll be using the Tensorflow and Keras libraries. This will be you most hands-on experience yet building and manipulating models. \n",
    "\n",
    "Let's start with importing those libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fef0d38-10db-4b8e-b3b5-85e85a36d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf   # Import the TensorFlow library, which provides tools for machine learning and deep learning.\n",
    "import pandas as pd  # Import the pandas library, used for data manipulation and analysis.\n",
    "\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting and visualization.\n",
    "# This line allows for the display of plots directly within the Jupyter notebook interface.\n",
    "%matplotlib inline  \n",
    " \n",
    "# Import Keras libraries\n",
    "from tensorflow.keras.models import Sequential  # Import the Sequential model: a linear stack of layers from Keras module in TensorFlow.\n",
    "from tensorflow.keras.layers import Dense  # Import the Dense layer: a fully connected neural network layer from Keras module in TensorFlow.\n",
    "from tensorflow.keras.layers import Flatten  # Import the Flatten layer: used to convert input data into a 1D array from Keras module in TensorFlow.\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy  # Import the SparseCategoricalCrossentropy loss function from Keras module in TensorFlow.\n",
    "from tensorflow.keras import layers # Import the whole layers library\n",
    "from tensorflow.keras import losses # Import the different loss functions\n",
    "from sklearn.metrics import confusion_matrix # Import the confusion matrix library\n",
    "import numpy as np # Import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49e0650-d63c-4ba4-b3f7-f8ced3670cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_display_data(path, batch_size=32, shape=(80,80,3), show_pictures=True):\n",
    "    # Define the directory path\n",
    "    directory_path = path\n",
    "    \n",
    "    # Define the batch size\n",
    "    batch_size = batch_size\n",
    "    \n",
    "    # Define the image size using the 1st 2 elements of the shape parameter\n",
    "    # We don't need the number of channels here, just the dimensions to use\n",
    "    image_size = shape[:2]\n",
    "    \n",
    "    # Load the dataset\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory_path,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=123,\n",
    "        labels='inferred',\n",
    "        label_mode='int'\n",
    "    )\n",
    "\n",
    "    if show_pictures:\n",
    "        # Get the class names\n",
    "        class_names = dataset.class_names\n",
    "        \n",
    "        # Display 3 images from each of the 2 categories\n",
    "        for i in range(2):\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            for images, labels in dataset.take(1):\n",
    "                images = images.numpy()\n",
    "                labels = labels.numpy()\n",
    "                for j in range(3):\n",
    "                    ax = plt.subplot(3, 3, j + 1)\n",
    "                    plt.imshow(images[labels == i][j].astype(\"uint8\"))\n",
    "                    plt.title(class_names[i])\n",
    "                    plt.axis(\"off\")\n",
    "            plt.show()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab69ef16-0273-45e9-a5c5-872d4ecb1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(activation='relu', shape=(80,80,3), num_classes=2):\n",
    "    '''A function to set up a model. \n",
    "          Takes in an activation function, shape for the input images, and number of classes.'''\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation=activation, input_shape=shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation=activation),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation=activation),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=activation),\n",
    "        layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b0e1c2-d4c8-4745-8ece-f130e1bed693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_train_model(dataset, model,\n",
    "                        loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                        optimizer='adam'):\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "    # Train the model\n",
    "    history = model.fit(dataset, epochs=10, validation_data=dataset, validation_split=0.2)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c72ef72-2d6b-404b-b3af-2e683bff8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 2\n",
    "\n",
    "def evaluate_model(dataset, model, history, num_classes=classes):\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(dataset)\n",
    "    print(f'Test loss: {loss}')\n",
    "    print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "    # Plot the training and validation loss over time\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the training and validation accuracy over time\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy over Time')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Get the class names\n",
    "    class_names = dataset.class_names\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = np.argmax(model.predict(dataset), axis=-1)\n",
    "    \n",
    "    # Get the true labels\n",
    "    y_true = np.concatenate([y for x, y in dataset], axis=0)\n",
    "    \n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks([0, 1], class_names)\n",
    "    plt.yticks([0, 1], class_names)\n",
    "    plt.colorbar()\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5fbaf3-5314-478f-8fcc-e6fe7a7b8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_whole_shabang(path, batch_size, shape, activation, loss, optimizer,show_pictures):\n",
    "    \n",
    "    dataset = load_display_data(path, batch_size, shape, show_pictures)\n",
    "    model = make_model(activation=activation, shape=shape, num_classes=classes)\n",
    "    model, history = compile_train_model(dataset, model, loss=loss,\n",
    "                        optimizer=optimizer)\n",
    "    evaluate_model(dataset, model, history, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12bb51fa-37ff-4302-993e-8354bee706de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n",
      "Using 0 files for training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory data/ships/shipsnet. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sushi\\Documents\\deep_learning_2_draft\\03_hyperparameter_optimization.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madagrad\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# adam, RMSprop, adagrad \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Run everything with these hyperparameters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m the_whole_shabang(path, batch_size, shape, activation, loss, optimizer, show_pictures)\n",
      "\u001b[1;32mc:\\Users\\sushi\\Documents\\deep_learning_2_draft\\03_hyperparameter_optimization.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mthe_whole_shabang\u001b[39m(path, batch_size, shape, activation, loss, optimizer,show_pictures):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     dataset \u001b[39m=\u001b[39m load_display_data(path, batch_size, shape, show_pictures)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model \u001b[39m=\u001b[39m make_model(activation\u001b[39m=\u001b[39mactivation, shape\u001b[39m=\u001b[39mshape, num_classes\u001b[39m=\u001b[39mclasses)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model, history \u001b[39m=\u001b[39m compile_train_model(dataset, model, loss\u001b[39m=\u001b[39mloss,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                         optimizer\u001b[39m=\u001b[39moptimizer)\n",
      "\u001b[1;32mc:\\Users\\sushi\\Documents\\deep_learning_2_draft\\03_hyperparameter_optimization.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m image_size \u001b[39m=\u001b[39m shape[:\u001b[39m2\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Load the dataset\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mpreprocessing\u001b[39m.\u001b[39;49mimage_dataset_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     directory_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     image_size\u001b[39m=\u001b[39;49mimage_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     subset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     labels\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minferred\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     label_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mif\u001b[39;00m show_pictures:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# Get the class names\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sushi/Documents/deep_learning_2_draft/03_hyperparameter_optimization.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     class_names \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mclass_names\n",
      "File \u001b[1;32mc:\\Users\\sushi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\image_dataset.py:303\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m image_paths, labels \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39mget_training_or_validation_split(\n\u001b[0;32m    300\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m image_paths:\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    304\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo images found in directory \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAllowed formats: \u001b[39m\u001b[39m{\u001b[39;00mALLOWLIST_FORMATS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m     )\n\u001b[0;32m    308\u001b[0m dataset \u001b[39m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[0;32m    309\u001b[0m     image_paths\u001b[39m=\u001b[39mimage_paths,\n\u001b[0;32m    310\u001b[0m     image_size\u001b[39m=\u001b[39mimage_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    316\u001b[0m     crop_to_aspect_ratio\u001b[39m=\u001b[39mcrop_to_aspect_ratio,\n\u001b[0;32m    317\u001b[0m )\n\u001b[0;32m    319\u001b[0m \u001b[39mif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: No images found in directory data/ships/shipsnet. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "path = 'data/ships/shipsnet' # Path to the data.\n",
    "                              # Only change this if you change the dataset or where it is located\n",
    "\n",
    "show_pictures = False # Show sample images from the dataset? Keep on at first, but may become distracting.\n",
    "                     # Set to False to turn off\n",
    "# Hyperparameters\n",
    "shape = (80,80,3)  # Dimensions to use for the images...the raw data are 80x80\n",
    "                   #  color images, but you could down-sample them\n",
    "                   #  or convert them to black and white if you wanted\n",
    "batch_size = 32  # What batch size to use\n",
    "classes = 2 # We have 2 classes in our example: ship and no_ship. \n",
    "            # Only change this if you change the dataset\n",
    "activation='relu' # The activation function is an important hyperparameter\n",
    "\n",
    "loss=SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer='adagrad'  # adam, RMSprop, adagrad \n",
    "\n",
    "# Run everything with these hyperparameters\n",
    "the_whole_shabang(path, batch_size, shape, activation, loss, optimizer, show_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
